import sounddevice as sd
import numpy as np
import whisper
import tempfile
import scipy.io.wavfile as wav
import signal
import sys

model = whisper.load_model("base")

def speech_to_text(duration=5):
    device_id = 13      # ë§ˆì´í¬(Realtek Audio), MME
    fs = 48000
    channels = 2

    print("ğŸ¤ ë§í•˜ì„¸ìš”...")

    audio = sd.rec(
        int(duration * fs),
        samplerate=fs,
        channels=1,
        dtype="float32",
        device=device_id
    )
    sd.wait()

    max_volume = np.max(np.abs(audio))
    print(f"ğŸ”Š max volume: {max_volume}")

    if max_volume < 0.001:
        print("âš ï¸ ë§ˆì´í¬ ì…ë ¥ì´ ê±°ì˜ ì—†ìŠµë‹ˆë‹¤.")
        return ""

    audio_mono = np.mean(audio, axis=1)

    with tempfile.NamedTemporaryFile(suffix=".wav", delete=False) as f:
        wav.write(f.name, fs, audio_mono)
        result = model.transcribe(f.name, language="ko")

    text = result["text"].strip()
    print("ğŸ“ ì¸ì‹ëœ í…ìŠ¤íŠ¸:", text)
    return text

# ì¢…ë£Œ ì‹ í˜¸ê°€ ì˜¤ë©´ ì‹¤í–‰ë  í•¨ìˆ˜ (ìœ ì–¸ì¥)
def signal_handler(sig, frame):
    print('ê°•ì œ ì¢…ë£Œ ì‹ í˜¸ ê°ì§€! ë§ˆì´í¬ë¥¼ ë‚´ë ¤ë†“ìŠµë‹ˆë‹¤...')
    # ì—¬ê¸°ì— sd.stop() ê°™ì€ ë§ˆì´í¬ ì •ì§€ ì½”ë“œ ì¶”ê°€
    sys.exit(0)

# ì‹ í˜¸ ë“±ë¡ (Dockerê°€ ë„ë¼ê³  í•  ë•Œ signal_handlerë¥¼ ì‹¤í–‰í•´ë¼)
signal.signal(signal.SIGTERM, signal_handler)
signal.signal(signal.SIGINT, signal_handler)