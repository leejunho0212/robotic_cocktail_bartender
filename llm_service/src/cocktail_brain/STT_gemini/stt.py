import sounddevice as sd
import numpy as np
import whisper
import tempfile
import scipy.io.wavfile as wav

model = whisper.load_model("base")

def speech_to_text(duration=5):
    device_id = 1      # ë§ˆì´í¬(Realtek Audio), MME
    fs = 48000
    channels = 2

    print("ğŸ¤ ë§í•˜ì„¸ìš”...")

    audio = sd.rec(
        int(duration * fs),
        samplerate=fs,
        channels=channels,
        dtype="float32",
        device=device_id
    )
    sd.wait()

    max_volume = np.max(np.abs(audio))
    print(f"ğŸ”Š max volume: {max_volume}")

    if max_volume < 0.001:
        print("âš ï¸ ë§ˆì´í¬ ì…ë ¥ì´ ê±°ì˜ ì—†ìŠµë‹ˆë‹¤.")
        return ""

    audio_mono = np.mean(audio, axis=1)

    with tempfile.NamedTemporaryFile(suffix=".wav", delete=False) as f:
        wav.write(f.name, fs, audio_mono)
        result = model.transcribe(f.name, language="ko")

    text = result["text"].strip()
    print("ğŸ“ ì¸ì‹ëœ í…ìŠ¤íŠ¸:", text)
    return text
